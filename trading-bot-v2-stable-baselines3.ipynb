{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Version History\n* v1: Just testing a few iterations over the 500,000 sample dataset\n* v2: Built custom feature extractor and 2,000,000 timesteps (Timed out)\n* v3: Decreasing timesteps to 1,800,000 (Timed out)\n* v4: Decreasing timesteps to 1,000,000 (Timed out)\n* v5: Decreasing timesteps to   500,000 (Timed out)\n* v6: Decreasing timesteps to   500,000 with GPU\n\n#### TODO:\n1. [x] Build custom feature extractor\n2. [ ] Build LR Scheduler\n3. [ ] Try out differnet net_archs","metadata":{}},{"cell_type":"markdown","source":"#### Links\n* [github](https://github.com/DLR-RM/stable-baselines3)\n* [readdocs.io](https://stable-baselines3.readthedocs.io/en/master/)\n* [readdocs.io (pdf)](https://stable-baselines3.readthedocs.io/_/downloads/en/master/pdf/)\n* [openai docs](https://openai.com/blog/openai-baselines-ppo/)\n* [detailed snake example](https://pythonprogramming.net/custom-environment-reinforcement-learning-stable-baselines-3-tutorial/)","metadata":{}},{"cell_type":"code","source":"!pip install -q stable_baselines3","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:02:16.460031Z","iopub.execute_input":"2022-04-18T17:02:16.460317Z","iopub.status.idle":"2022-04-18T17:02:29.417745Z","shell.execute_reply.started":"2022-04-18T17:02:16.460285Z","shell.execute_reply":"2022-04-18T17:02:29.416844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport math\n\nimport gym\nfrom gym import spaces\n\nfrom stable_baselines3 import DQN\n\nimport matplotlib.pyplot as plt\n\nfrom collections import deque\n\nfrom typing import Any, Dict, List, Optional, Type\n\nimport gym\nimport torch as th\nfrom torch import nn\n\nfrom stable_baselines3.common.policies import BasePolicy\nfrom stable_baselines3.common.torch_layers import (\n    BaseFeaturesExtractor,\n    CombinedExtractor,\n    FlattenExtractor,\n    NatureCNN,\n    create_mlp,\n)\n\nfrom stable_baselines3.common.type_aliases import Schedule","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T17:02:29.42005Z","iopub.execute_input":"2022-04-18T17:02:29.42029Z","iopub.status.idle":"2022-04-18T17:02:31.673828Z","shell.execute_reply.started":"2022-04-18T17:02:29.42026Z","shell.execute_reply":"2022-04-18T17:02:31.673038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG():\n    DEVICE = th.device(\"cuda\") if th.cuda.is_available() else th.device(\"cpu\")\n    BS = 512\n    N_ACTIONS = 3\n    SEQ_LEN = 15\n    EPOCHS = 20\n    CASH = 25_000  # in USD\n    LR = 1e-3\n    GAMMA = 0.99\n    EPS = 1.\n    EPS_DEC = .9999\n    EPS_MIN = 1e-2\n    MEM_SIZE = 1000\n    REPLACE_CNT = 1000\n    N_FEATS = 76\n    N_SHARES = 100\n    MIN_SHARES = 0\n    MAX_SHARES = 300\n    CASH_BUFFER = 500  # in USD\n    HIDDEN_SZ = 200\n    NLAYERS = 2\n    SEQ_LEN = 1","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T17:02:31.675099Z","iopub.execute_input":"2022-04-18T17:02:31.676276Z","iopub.status.idle":"2022-04-18T17:02:31.739169Z","shell.execute_reply.started":"2022-04-18T17:02:31.676242Z","shell.execute_reply":"2022-04-18T17:02:31.737971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MartketFeatures(BaseFeaturesExtractor):\n    \"\"\"\n    :param observation_space: (gym.Space)\n    :param features_dim: (int) Number of features extracted.\n        This corresponds to the number of unit for the last layer.\n    \"\"\"\n    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n        super(MartketFeatures, self).__init__(observation_space, features_dim)\n        emb_dim = 0\n        for _,i in EMB_DIMS:\n            emb_dim += i\n        n_cat_feats = 15\n        input_dim = observation_space.shape[1] + emb_dim - n_cat_feats\n        self.emb_layers = nn.ModuleList([nn.Embedding(i,j) for i,j in EMB_DIMS])\n\n        self.gru = nn.GRU(input_dim, features_dim, CONFIG.NLAYERS, batch_first=True)\n        self.hn = th.zeros((CONFIG.NLAYERS, CONFIG.SEQ_LEN, features_dim), device=CONFIG.DEVICE)\n\n        self.linear = nn.Sequential(nn.Linear(features_dim,features_dim), nn.ReLU())\n\n    def forward(self, observations: th.Tensor) -> th.Tensor:\n        observations = observations\n        cats = observations[:,:,:15].long()\n        conts = observations[:,:,15:].squeeze(1)\n        \n        emb = [emb_layer(cats[:,:,i]).squeeze(1) for i,emb_layer in enumerate(self.emb_layers)]\n\n        emb = th.cat(emb,1)\n        \n        gru_inp = th.cat([emb, conts],1).float().unsqueeze(0)\n        output, self.hn = self.gru(gru_inp, self.hn.detach())\n        \n        output = output.squeeze(0)\n        return self.linear(output)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:02:31.742053Z","iopub.execute_input":"2022-04-18T17:02:31.742728Z","iopub.status.idle":"2022-04-18T17:02:31.758485Z","shell.execute_reply.started":"2022-04-18T17:02:31.742681Z","shell.execute_reply":"2022-04-18T17:02:31.757499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MarketEnv(gym.Env):\n    metadata = {'render.modes': ['human']}\n\n    def __init__(self, df, closing_prices):\n        super(MarketEnv, self).__init__()\n        self.action_space = spaces.Discrete(CONFIG.N_ACTIONS)  # {Buy: 0, Sell: 1, Hold: 2}\n        self.observation_space = spaces.Box(low=0, high=1, shape=((1,CONFIG.N_FEATS)))\n        self.closing_series = closing_prices\n        self.closing_iter = closing_price.iteritems()\n        _,self.close = next(self.closing_iter)\n        self.historicals = df\n        self.historicals_iter = df.itertuples(index=False)\n        self.observation = th.tensor(next(self.historicals_iter)).unsqueeze(0)\n        \n        self.orders = deque(maxlen=60) # remembers the last x trades\n\n        self.cash = CONFIG.CASH\n        self.shares_owned = 0\n        self.prev_close = self.close\n        \n        self.plot_init = False\n\n    def step(self, action):\n        reward = 0\n        done = False\n        info = {}\n\n        assets_worth_prev = self.cash + self.shares_owned * self.prev_close\n        assets_worth_now = self.cash + self.shares_owned * self.close\n        self.value = assets_worth_now\n        \n        def reward_calc(x):\n            return 1 / (1 + math.exp(-x/100))\n        \n        if action == 0:  # Buy\n            if self.shares_owned < CONFIG.MAX_SHARES:\n                if self.close * CONFIG.N_SHARES + CONFIG.CASH_BUFFER < self.cash:\n                    self.cash -= self.close * CONFIG.N_SHARES\n                    self.shares_owned += CONFIG.N_SHARES\n                    self.orders.append(-1 * self.close)\n                    reward = reward_calc(sum(self.orders))\n                else:\n                    done = True\n                    reward = -1\n            else:\n                reward = -.2\n        elif action == 1: # Sell\n            if self.shares_owned > CONFIG.MIN_SHARES:\n                self.cash += CONFIG.N_SHARES * self.close\n                self.shares_owned -= CONFIG.N_SHARES\n                self.orders.append(self.close)\n                reward = reward_calc(sum(self.orders))\n            else:\n                reward = -1\n        else:\n            reward = -.1\n\n        self.prev_close = self.close\n        \n        try:\n            _,self.close = next(self.closing_iter)\n            self.observation = th.tensor(next(self.historicals_iter)).unsqueeze(0)\n        except StopIteration:\n            done = True\n        \n        return self.observation, reward, done, info\n\n    def reset(self):\n        self.cash = CONFIG.CASH\n        self.shares_owned = 0\n        self.historicals_iter = self.historicals.itertuples(index=False)\n        self.closing_iter = self.closing_series.iteritems()\n        _,self.close = next(self.closing_iter)\n        self.observation = th.tensor(next(self.historicals_iter)).unsqueeze(0)\n        return self.observation\n  \n    def render(self, assets, baseline):\n        baseline = [x*CONFIG.MAX_SHARES for x in baseline]\n        plt.figure(figsize=(35,10))\n        plt.plot(np.linspace(0,len(assets),len(assets)), assets, color='red', label='Test')\n        plt.plot(np.linspace(0,len(baseline),len(baseline)), baseline, color='gray', label='Baseline');\n        plt.title('Trained Models vs Baseline Buy and Hold')\n        plt.xlabel('Minutes')\n        plt.xlim(xmin=-3)\n        plt.ylabel('Account Value')\n        plt.legend(bbox_to_anchor=(1.0, 1.03), loc='upper left')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:02:31.760085Z","iopub.execute_input":"2022-04-18T17:02:31.76039Z","iopub.status.idle":"2022-04-18T17:02:31.785851Z","shell.execute_reply.started":"2022-04-18T17:02:31.760347Z","shell.execute_reply":"2022-04-18T17:02:31.784748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nfrom stable_baselines3.common.callbacks import BaseCallback\n\nclass ProgbarCallback(BaseCallback):\n    def __init__(self):\n        super().__init__()\n        self.progress_bar = None\n    \n    def _on_training_start(self):\n        self.progress_bar = tqdm(total=self.locals['total_timesteps'])\n    \n    def _on_step(self):\n        self.progress_bar.update(1)\n        return True\n\n    def _on_training_end(self):\n        self.progress_bar.close()\n        self.progress_bar = None","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:02:31.787516Z","iopub.execute_input":"2022-04-18T17:02:31.788124Z","iopub.status.idle":"2022-04-18T17:02:31.799257Z","shell.execute_reply.started":"2022-04-18T17:02:31.788076Z","shell.execute_reply":"2022-04-18T17:02:31.798294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def categorify(df,split):\n    df = df.astype('int')\n    cats = df.columns.tolist()\n    \n    embs = {}\n    \n    for col in cats:\n        embs[col] = df[col].unique().tolist()\n        embs[col].sort()\n\n    for key in embs:\n        for idx,val in enumerate(embs[key]):\n            df[key].replace(val,idx,inplace=True)\n            \n    df = df.astype('category')\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:02:31.801147Z","iopub.execute_input":"2022-04-18T17:02:31.80168Z","iopub.status.idle":"2022-04-18T17:02:31.81033Z","shell.execute_reply.started":"2022-04-18T17:02:31.801634Z","shell.execute_reply":"2022-04-18T17:02:31.809336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_pickle(\"../input/historicals/first_500000.pkl\").iloc[:,:-4]\ndf.iloc[:,:15] = categorify(df.iloc[:,:15],15)\n\ncat_nuniq = [df[col].nunique() for col in df.iloc[:,:15]]\nEMB_DIMS = [(x, min(50, (x + 1) // 2)) for x in cat_nuniq]\n\nclosing_price = df.loc[:,'close_spy']\ncats = df.iloc[:,:15]\nconts = df.iloc[:,15:]\n\nmean = conts.mean()\nstd = conts.std()\nnormalized_df = (conts-mean)/std\ncombined_df = pd.concat((cats,normalized_df),axis=1)\n\nenv = MarketEnv(combined_df, closing_price)\n\ntqdm_callback = ProgbarCallback()\n\npolicy_kwargs = dict(net_arch=[64,64],\n                     features_extractor_class=MartketFeatures,\n                     features_extractor_kwargs=dict(features_dim=256),\n                     normalize_images=False,\n                    )\n\nmodel = DQN(\"MlpPolicy\",\n            env,\n            learning_rate=CONFIG.LR,\n            learning_starts=2400,\n            batch_size=CONFIG.BS,\n            train_freq=480,\n            target_update_interval=7200,\n            exploration_fraction=0.2,\n            exploration_initial_eps=1.,\n            exploration_final_eps=.01,\n            gamma=CONFIG.GAMMA,\n            policy_kwargs=policy_kwargs,\n            verbose=0,\n            seed=42,\n            device=CONFIG.DEVICE,\n            _init_setup_model=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:02:31.81201Z","iopub.execute_input":"2022-04-18T17:02:31.812551Z","iopub.status.idle":"2022-04-18T17:02:38.524543Z","shell.execute_reply.started":"2022-04-18T17:02:31.812464Z","shell.execute_reply":"2022-04-18T17:02:38.523712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel.learn(total_timesteps=500_000, callback=tqdm_callback)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-04-18T17:02:38.525985Z","iopub.execute_input":"2022-04-18T17:02:38.52627Z","iopub.status.idle":"2022-04-18T17:18:55.372992Z","shell.execute_reply.started":"2022-04-18T17:02:38.52623Z","shell.execute_reply":"2022-04-18T17:18:55.37227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"PPO_Market_Bot_GPU\")\n# model = DQN.load(\"PPO_Market_Bot\")\nobs = env.reset()\nassets = [None] * 3_000_000\nclosing = [None] * 3_000_000\nactions = [None] * 3_000_000\nidx = 0\nfor _ in range(500_000):\n    action, _states = model.predict(obs)\n    obs, reward, done, info = env.step(action)\n    assets[idx] = env.value\n    closing[idx] = env.close\n    actions[idx] = action\n    idx += 1\nassets = [x for x in assets if x!=None]\nclosing = [x for x in closing if x!=None]\nactions = [x for x in actions if x!=None]\nenv.render(assets, closing)","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:18:55.378237Z","iopub.execute_input":"2022-04-18T17:18:55.380309Z","iopub.status.idle":"2022-04-18T17:30:15.818821Z","shell.execute_reply.started":"2022-04-18T17:18:55.380268Z","shell.execute_reply":"2022-04-18T17:30:15.817741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"string1 = \"Shares Owned:  \"\nstring2 = \"Closing Price: $\"\nstring3 = \"Leftover Cash: $\"\nstring4 = \"Shares Final Value: $\"\nstring5 = \"Total Final Value of all Assets: $\"\nprint(f\"{string1:>35}{env.shares_owned:>11}\\n{string2:>35}{env.close:>11,.2f}\\n{string3:>35}{env.cash:>11,.2f}\\n{string4:>35}{env.shares_owned * env.close:>11,.2f}\\n{string5:>35}{env.value:>11,.2f}\\n\")\n\nt = pd.Series(actions, dtype=int)\nfor unique in t.unique().tolist():\n    if unique==0:\n        print(f\" Buy Orders: {len(t[t==unique]):>6,}\")\n    elif unique==1:\n        print(f\"Sell Orders: {len(t[t==unique]):>6,}\")\n    else:\n        print(f\"       Pass: {len(t[t==unique]):>6,}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-18T17:30:15.820038Z","iopub.execute_input":"2022-04-18T17:30:15.820286Z","iopub.status.idle":"2022-04-18T17:30:15.911973Z","shell.execute_reply.started":"2022-04-18T17:30:15.820255Z","shell.execute_reply":"2022-04-18T17:30:15.91117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}